{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1p5BlXEkOyY"
   },
   "source": [
    "# Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Disguise proper names in an email"
   ],
   "metadata": {
    "id": "B8pRfInpLokG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "email = \"\"\"\n",
    "Уважаемая Эльвира Геннадьевна,\n",
    "\n",
    "Как шеф-повар, я должен выразить свою обеспокоенность слухами о появлении плесени вблизи некоторых кухонь в корпусе 13 по адресу: Льва Толстого, 42. Обращаю ваше внимание на то, что любые продукты, обрабатываемые, приготавливаемые или потребляемые вблизи плесени, могут быть заражены и небезопасны для употребления.\n",
    "\n",
    "Если эти сообщения найдут подтверждения, мне придется закрыть несколько столовых. Возможно распределение нагрузки на кухни в корпусах:\n",
    "№9 площадь Гагарина, 99\n",
    "№10 улица Южная, 10\n",
    "\n",
    "С уважением,\n",
    "Алексей Мартынов.\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "j0R4An8_LRU-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMXh5pV0kacc"
   },
   "outputs": [],
   "source": [
    "! pip install -q pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "mystem = Mystem()\n",
    "\n",
    "lines = email.split('\\n')\n",
    "\n",
    "def is_proper_name(word):\n",
    "    parsed_word = mystem.analyze(word)[0]\n",
    "    if 'analysis' in parsed_word and len(parsed_word['analysis']) > 0 and 'gr' in parsed_word['analysis'][0]:\n",
    "        gr = parsed_word['analysis'][0]['gr']\n",
    "        if 'имя' in gr or 'фам' in gr or 'отч' in gr or 'гео' in gr:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "last_word_was_proper_name = False\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    words = lines[i].split()\n",
    "    for j in range(len(words)):\n",
    "        if is_proper_name(words[j]) or 'улица' in words[j - 1]:\n",
    "          if last_word_was_proper_name == False:\n",
    "            words[j] = '[ИМЯ]'\n",
    "          else:\n",
    "            words[j] = ''\n",
    "          last_word_was_proper_name = True\n",
    "        else:\n",
    "          last_word_was_proper_name = False\n",
    "    lines[i] = ' '.join(words)\n",
    "\n",
    "masked_email = '\\n'.join(lines)\n",
    "\n",
    "print(masked_email)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qyt4btViMk54",
    "outputId": "28947de3-16a6-4d64-bd75-6d315070af82"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Уважаемая [ИМЯ] \n",
      "\n",
      "Как шеф-повар, я должен выразить свою обеспокоенность слухами о появлении плесени вблизи некоторых кухонь в корпусе 13 по адресу: [ИМЯ]  42. Обращаю ваше внимание на то, что любые продукты, обрабатываемые, приготавливаемые или потребляемые вблизи плесени, могут быть заражены и небезопасны для употребления.\n",
      "\n",
      "Если эти сообщения найдут подтверждения, мне придется закрыть несколько столовых. Возможно распределение нагрузки на кухни в корпусах:\n",
      "№9 площадь [ИМЯ] 99\n",
      "№10 улица [ИМЯ] 10\n",
      "\n",
      "С уважением,\n",
      "[ИМЯ] \n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Replace pymorphy selected object in the wikipedia article with another object (with a declination)"
   ],
   "metadata": {
    "id": "rwN-KYu4qTzx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Example of input data\n",
    "orig_wikitext = \"\"\"Стрекозы (лат. Odonáta) — отряд древних летающих насекомых, насчитывающий в мировой фауне свыше 6650 видов. Это относительно крупные насекомые, с подвижной головой, большими глазами, короткими щетинковидными усиками, удлинённым стройным брюшком и четырьмя прозрачными крыльями с густой сетью жилок. Стрекозы — активные специализированные хищники, которые питаются насекомыми, пойманными на лету. Представители отряда широко распространены по миру, встречаясь на всех материках, исключая Антарктиду.\n",
    "Все представители отряда ведут амфибионтный образ жизни — яйца и личинки развиваются в водной среде, а имаго (взрослые) обитают на суше, освоив воздушную среду и став прекрасными летунами. Взрослые стрекозы не ограничиваются в выборе места обитания одними только берегами водоёмов и могут улетать от них на значительные расстояния, встречаясь на лугах, опушках лесов и даже в населённых пунктах. Развитие с неполным превращением: имеются стадии яйца, личинки и имаго. Личинки (их называют также нимфами или наядами) развиваются в водоёмах различных типов — главным образом в стоячих озёрах, прудах и старицах рек, а также в ручьях, реках и болотистых водоёмах, вплоть до созданных человеком прудов и канав с водой. Как и взрослые стрекозы, личинки являются хищниками. Они охотятся на водных насекомых и прочих беспозвоночных.\n",
    "Стрекозы имеют большое значение для человека. Велика их роль в регуляции численности кровососущих насекомых, ряда насекомых-вредителей сельского и лесного хозяйства. В некоторых случаях личинки стрекоз могут приносить вред, например, уничтожая мальков в рыбоводных прудах либо составляя им пищевую конкуренцию. Кроме того, личинки некоторых видов могут являться промежуточными хозяевами гельминтов.\"\"\"\n",
    "\n",
    "# Example of output data\n",
    "result_wikitext = \"\"\"Годзиллы (лат. Odonáta) — отряд древних летающих насекомых, насчитывающий в мировой фауне свыше 6650 видов. Это относительно крупные насекомые, с подвижной головой, большими глазами, короткими щетинковидными усиками, удлинённым стройным брюшком и четырьмя прозрачными крыльями с густой сетью жилок. Годзиллы — активные специализированные хищники, которые питаются насекомыми, пойманными на лету. Представители отряда широко распространены по миру, встречаясь на всех материках, исключая антарктиду. \n",
    "Все представители отряда ведут амфибионтный образ жизни — яйца и личинки развиваются в водной среде, а имаго (взрослые) обитают на суше, освоив воздушную среду и став прекрасными летунами. Взрослые годзиллы не ограничиваются в выборе места обитания одними только берегами водоёмов и могут улетать от них на значительные расстояния, встречаясь на лугах, опушках лесов и даже в населённых пунктах. Развитие с неполным превращением: имеются стадии яйца, личинки и имаго. Личинки (их называют также нимфами или наядами) развиваются в водоёмах различных типов — главным образом в стоячих озёрах, прудах и старицах рек, а также в ручьях, реках и болотистых водоёмах, вплоть до созданных человеком прудов и канав с водой. Как и взрослые годзиллы, личинки являются хищниками. Они охотятся на водных насекомых и прочих беспозвоночных. \n",
    "Годзиллы имеют большое значение для человека. Велика их роль в регуляции численности кровососущих насекомых, ряда насекомых- вредителей сельского и лесного хозяйства. В некоторых случаях личинки годзилл могут приносить вред, например, уничтожая мальков в рыбоводных прудах либо составляя им пищевую конкуренцию. Кроме того, личинки некоторых видов могут являться промежуточными хозяевами гельминтов.\"\"\""
   ],
   "metadata": {
    "id": "8XrDUlrVu-mM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "original_word = \"стрекоза\"\n",
    "replacement_word = \"годзилла\"\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def get_forms(word):\n",
    "  word_lexemes = morph.parse(word)[0].lexeme\n",
    "  word_lexemes_words = [word_lexeme.word for word_lexeme in word_lexemes]\n",
    "  word_lexemes_words += [word.title() for word in word_lexemes_words]\n",
    "\n",
    "  return word_lexemes_words\n",
    "\n",
    "orig_forms = get_forms(original_word)\n",
    "repl_forms = get_forms(replacement_word)\n",
    "\n",
    "result_wikitext = orig_wikitext\n",
    "for index, word_form in enumerate(orig_forms):\n",
    "  result_wikitext = re.sub(r'\\b' + word_form + r'\\b', repl_forms[index], orig_wikitext)\n",
    "\n",
    "print(result_wikitext)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlVnO19l1sxx",
    "outputId": "da569629-c6cf-48a1-f3e8-ddcdb6ce2a83"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Стрекозы (лат. Odonáta) — отряд древних летающих насекомых, насчитывающий в мировой фауне свыше 6650 видов. Это относительно крупные насекомые, с подвижной головой, большими глазами, короткими щетинковидными усиками, удлинённым стройным брюшком и четырьмя прозрачными крыльями с густой сетью жилок. Стрекозы — активные специализированные хищники, которые питаются насекомыми, пойманными на лету. Представители отряда широко распространены по миру, встречаясь на всех материках, исключая Антарктиду.\n",
      "Все представители отряда ведут амфибионтный образ жизни — яйца и личинки развиваются в водной среде, а имаго (взрослые) обитают на суше, освоив воздушную среду и став прекрасными летунами. Взрослые стрекозы не ограничиваются в выборе места обитания одними только берегами водоёмов и могут улетать от них на значительные расстояния, встречаясь на лугах, опушках лесов и даже в населённых пунктах. Развитие с неполным превращением: имеются стадии яйца, личинки и имаго. Личинки (их называют также нимфами или наядами) развиваются в водоёмах различных типов — главным образом в стоячих озёрах, прудах и старицах рек, а также в ручьях, реках и болотистых водоёмах, вплоть до созданных человеком прудов и канав с водой. Как и взрослые стрекозы, личинки являются хищниками. Они охотятся на водных насекомых и прочих беспозвоночных.\n",
      "Стрекозы имеют большое значение для человека. Велика их роль в регуляции численности кровососущих насекомых, ряда насекомых-вредителей сельского и лесного хозяйства. В некоторых случаях личинки стрекоз могут приносить вред, например, уничтожая мальков в рыбоводных прудах либо составляя им пищевую конкуренцию. Кроме того, личинки некоторых видов могут являться промежуточными хозяевами гельминтов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Comparison of morphological analyzers"
   ],
   "metadata": {
    "id": "prU2-JNCrIyE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install -q natasha"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgJy0aH4DHKt",
    "outputId": "d8eabd27-f043-4d3f-9414-f50c317c8f26"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m34.4/34.4 MB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.7/46.7 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for intervaltree (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pymorphy2\n",
    "import natasha\n",
    "\n",
    "# text = \"Дома дружнее всего, друзьям дружнее всегда.\"\n",
    "text = \"\"\"Стрекозы (лат. Odonáta) — отряд древних летающих насекомых, насчитывающий в мировой фауне свыше 6650 видов. Это относительно крупные насекомые, с подвижной головой, большими глазами, короткими щетинковидными усиками, удлинённым стройным брюшком и четырьмя прозрачными крыльями с густой сетью жилок. Стрекозы — активные специализированные хищники, которые питаются насекомыми, пойманными на лету. Представители отряда широко распространены по миру, встречаясь на всех материках, исключая Антарктиду.\n",
    "Все представители отряда ведут амфибионтный образ жизни — яйца и личинки развиваются в водной среде, а имаго (взрослые) обитают на суше, освоив воздушную среду и став прекрасными летунами. Взрослые стрекозы не ограничиваются в выборе места обитания одними только берегами водоёмов и могут улетать от них на значительные расстояния, встречаясь на лугах, опушках лесов и даже в населённых пунктах. Развитие с неполным превращением: имеются стадии яйца, личинки и имаго. Личинки (их называют также нимфами или наядами) развиваются в водоёмах различных типов — главным образом в стоячих озёрах, прудах и старицах рек, а также в ручьях, реках и болотистых водоёмах, вплоть до созданных человеком прудов и канав с водой. Как и взрослые стрекозы, личинки являются хищниками. Они охотятся на водных насекомых и прочих беспозвоночных.\n",
    "Стрекозы имеют большое значение для человека. Велика их роль в регуляции численности кровососущих насекомых, ряда насекомых-вредителей сельского и лесного хозяйства. В некоторых случаях личинки стрекоз могут приносить вред, например, уничтожая мальков в рыбоводных прудах либо составляя им пищевую конкуренцию. Кроме того, личинки некоторых видов могут являться промежуточными хозяевами гельминтов.\"\"\"\n",
    "\n",
    "morph1 = pymorphy2.MorphAnalyzer()\n",
    "morph2 = natasha.MorphVocab()\n",
    "\n",
    "def process_text(morph_analyzer):\n",
    "  lemmas = []\n",
    "  tags = []\n",
    "  for token in text.split():\n",
    "    parse_result = morph_analyzer.parse(token)[0]\n",
    "    # normal_form property will be the same in both analyzers\n",
    "    if 'MorphVocab' == type(morph_analyzer).__name__:\n",
    "      lemmas.append(parse_result.normal)\n",
    "    else:\n",
    "      lemmas.append(parse_result.word)\n",
    "    tags.append(parse_result.tag)\n",
    "\n",
    "  return lemmas, tags\n",
    "\n",
    "lemmas1, tags1 = process_text(morph1)\n",
    "lemmas2, tags2 = process_text(morph2)\n",
    "\n",
    "j = 0\n",
    "for i in range(len(text.split())):\n",
    "  if lemmas1[i] != lemmas2[i]:\n",
    "      print(f\"Токен: {text.split()[i]}\")\n",
    "      print(f\"Лемма (pymorphy2): {lemmas1[i]}\")\n",
    "      print(f\"Лемма (natasha): {lemmas2[i]}\")\n",
    "      print(f\"Теги (pymorphy2): {tags1[i]}\")\n",
    "      print(f\"Теги (natasha): {tags2[i]}\")\n",
    "      print(\"-\" * 80)\n",
    "      j += 1\n",
    "  if j > 2:\n",
    "    break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjJBLOAZsGRv",
    "outputId": "2749c7c9-4fa8-4eb3-f98a-65b55b3a25d3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Токен: Стрекозы\n",
      "Лемма (pymorphy2): стрекозы\n",
      "Лемма (natasha): стрекоза\n",
      "Теги (pymorphy2): NOUN,anim,femn sing,gent\n",
      "Теги (natasha): NOUN,anim,femn sing,gent\n",
      "--------------------------------------------------------------------------------\n",
      "Токен: древних\n",
      "Лемма (pymorphy2): древних\n",
      "Лемма (natasha): древний\n",
      "Теги (pymorphy2): ADJF,Qual plur,gent\n",
      "Теги (natasha): ADJF,Qual plur,gent\n",
      "--------------------------------------------------------------------------------\n",
      "Токен: летающих\n",
      "Лемма (pymorphy2): летающих\n",
      "Лемма (natasha): летать\n",
      "Теги (pymorphy2): PRTF,impf,intr,pres,actv plur,gent\n",
      "Теги (natasha): PRTF,impf,intr,pres,actv plur,gent\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Token visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! wget -q https://www.dropbox.com/s/ug0b4pvuynwj4pe/news_science.zip && unzip -q news_science.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "data = []\n",
    "for path in glob.glob('./news_science/*'): # paths are [./news_science/news1_txt, ./news_science/sci.comp_txt]\n",
    "  texts = []\n",
    "  for filename in tqdm(glob.glob(path + '/*.txt')):\n",
    "    texts.append(open(filename, 'r').read().strip()) # append trimmed content of each file in path to texts\n",
    "  \n",
    "  data.append(pd.DataFrame({'text': texts})) # append dataframe\n",
    "  # get first 3 letters from last chain of path (news1_txt or sci.comp_txt) result: 'new' or 'sci'\n",
    "  # and add column genre to the last dataframe in list\n",
    "  data[-1]['genre'] = path.split('/')[-1][:3]\n",
    "\n",
    "data = pd.concat(data) # data was a list of dataframes, now it is dataframe itself\n",
    "data.sample(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "# nltk.download('punkt') # instruments for tokenization into words and sentances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "# the following regular expression is equivalent to apply\n",
    "# re.sub(r'[^\\w\\s]', '', text) and then re.sub(r'\\s+', ' ', text)\n",
    "# replace_spaces = lambda match: ' ' if match.group(0).isspace() else ''\n",
    "# clean_text_fn = lambda text: re.sub(r'[^\\w\\s]|(\\s+)', replace_spaces, text)\n",
    "# data[\"text_cleaned\"] = data[\"text\"].apply(clean_text_fn)\n",
    "\n",
    "# data[\"text_cleaned\"] = data[\"text\"].apply(lambda text: re.sub(r'[^\\S\\n]+', ' ', text))\n",
    "data[\"text_cleaned\"] = data[\"text_cleaned\"].apply(lambda text: re.sub(r'[^\\S\\n]+', ' ', text))\n",
    "data[\"text_cleaned\"] = data[\"text_cleaned\"].apply(lambda text: re.sub(r'\\n', '. ', text))\n",
    "data[\"text_cleaned\"] = data[\"text_cleaned\"].apply(lambda text: re.sub(r'\\s\\.', '. ', text))\n",
    "data[\"text_cleaned\"] = data[\"text_cleaned\"].apply(lambda text: text.lower())\n",
    "\n",
    "sentences = nltk.sent_tokenize(' '.join(data[\"text_cleaned\"]))\n",
    "tokenized_sentences = []\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "for sentence in sentences:\n",
    "  words = nltk.word_tokenize(re.sub(r'[^\\w\\s\\-]', '', sentence))\n",
    "  filtered_words = [word for word in words if word not in stop_words]\n",
    "  tokenized_sentences.append(filtered_words)\n",
    "\n",
    "print(tokenized_sentences)\n",
    "data.sample(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Создание экземпляра модели Word2Vec\n",
    "model = Word2Vec(vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Обучение модели на вашем корпусе текста (список списков токенов)\n",
    "model.build_vocab(tokenized_sentences)\n",
    "model.train(data[\"text_cleaned\"], total_examples=len(data[\"text_cleaned\"]), epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "# all_tokens = []\n",
    "# for sentence in tokenized_sentences:\n",
    "#     for token in sentence:\n",
    "#         all_tokens.append(token)\n",
    "# random_tokens = ['кошка', 'собака']\n",
    "random_tokens = random.sample([token for sentence in tokenized_sentences for token in sentence], 100)\n",
    "print(random_tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checking if all the tokens are present in the model\n",
    "# some words can be absent if min_count > 1 \n",
    "for word in random_tokens:\n",
    "    if word not in model.wv.key_to_index:\n",
    "        print(f'The word \"{word}\" is absent from Word2Vec.')\n",
    "        raise SystemExit\n",
    "print('all tokens are present in Word2Vec')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectors = [model.wv[word] for word in random_tokens]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Преобразование списка vectors в массив NumPy\n",
    "vectors_np = np.array(vectors)\n",
    "\n",
    "# Applying of t-SNE algorithm\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embedded = tsne.fit_transform(vectors_np)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def get_pos_from_token(token):\n",
    "    parsed_token = morph.parse(token)[0]\n",
    "    pos = parsed_token.tag.cyr_repr\n",
    "    return pos.lower() if pos else None\n",
    "\n",
    "print('the word \"' + random_tokens[1] + '\" is a ' + get_pos_from_token(random_tokens[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "scatter = ax.scatter(embedded[:, 0], embedded[:, 1], c='b', marker='.', s=50)\n",
    "\n",
    "font_size = 8  # Размер шрифта\n",
    "# Добавление названий токенов и их частей речи\n",
    "for i, token in enumerate(random_tokens):\n",
    "    pos = get_pos_from_token(token)  # Функция для получения части речи из токена\n",
    "    # ax.annotate(f\"{token} ({pos})\", (embedded[i, 0], embedded[i, 1]), fontsize=font_size)\n",
    "    ax.annotate(f\"{token} ({pos})\", (embedded[i, 0], embedded[i, 1]), fontsize=font_size, ha='center', va='bottom')\n",
    "    # ax.arrow(embedded[i, 0], embedded[i, 1], 0, 0, head_width=0.2, head_length=2, fc='black', ec='black')\n",
    "    # ax.plot([embedded[i, 0], embedded[i, 0]], [embedded[i, 1], embedded[i, 1]], 'k--', linewidth=0.5)  # Линия-связь\n",
    "\n",
    "# Установка меток осей и заголовка графика\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title('Word2Vec Token Visualization with t-SNE')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}